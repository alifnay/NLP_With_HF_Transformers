{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **HuggingFace Transformers NLP Pipelines!**"
      ],
      "metadata": {
        "id": "CztodpmQM11q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "> Library Installation\n",
        "\n"
      ],
      "metadata": {
        "id": "fTF1AT9Gc66A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "id": "6dtAhiTAMmYN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "039f1ee9-1c2e-4209-c252-2f7afdce9044"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.24.7)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.6)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> Import Library"
      ],
      "metadata": {
        "id": "t6vNsuT7dJ0r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline"
      ],
      "metadata": {
        "id": "w3g0V_WTMpwB"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "> a) Zero Shot Classification\n",
        "\n"
      ],
      "metadata": {
        "id": "lKB2Ab6hde4X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classifier = pipeline(\"zero-shot-classification\")\n",
        "classifier(\n",
        "    \"The stock market saw a significant increase today, with tech stocks leading the way.\",\n",
        "    candidate_labels=[\"finance\", \"economy\", \"Investment\", \"Market\"],\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Phpirw-Cdb-6",
        "outputId": "ac529d23-65d1-4edb-fada-25ce127d4e86"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to facebook/bart-large-mnli and revision c626438 (https://huggingface.co/facebook/bart-large-mnli).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
            "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'sequence': 'The stock market saw a significant increase today, with tech stocks leading the way.',\n",
              " 'labels': ['Market', 'Investment', 'finance', 'economy'],\n",
              " 'scores': [0.6858528256416321,\n",
              "  0.14780130982398987,\n",
              "  0.12047457695007324,\n",
              "  0.045871272683143616]}"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classifier = pipeline(\"zero-shot-classification\")\n",
        "classifier(\n",
        "    \"The government announced a new policy to tackle climate change and reduce carbon emissions.\",\n",
        "    candidate_labels=[\"environment\", \"politics\", \"climate change\", \"carbon emissions\"],\n",
        ")"
      ],
      "metadata": {
        "id": "iMxLGaXEehDl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe285911-226c-4ce0-fd08-8bd761b92d1e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to facebook/bart-large-mnli and revision c626438 (https://huggingface.co/facebook/bart-large-mnli).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
            "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'sequence': 'The government announced a new policy to tackle climate change and reduce carbon emissions.',\n",
              " 'labels': ['carbon emissions', 'climate change', 'environment', 'politics'],\n",
              " 'scores': [0.4701637029647827,\n",
              "  0.37425944209098816,\n",
              "  0.1389905959367752,\n",
              "  0.01658623479306698]}"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classifier = pipeline(\"zero-shot-classification\")\n",
        "classifier(\n",
        "    \"The latest smartphone features a high-resolution camera, faster processor, and a sleek design.\",\n",
        "    candidate_labels=[\"technology\", \"device\", \"fashion\", \"health\"],\n",
        ")"
      ],
      "metadata": {
        "id": "jXpng5rlgVDS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "62b8741d-17fa-425a-e760-7b7f3096d6b4"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to facebook/bart-large-mnli and revision c626438 (https://huggingface.co/facebook/bart-large-mnli).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
            "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'sequence': 'The latest smartphone features a high-resolution camera, faster processor, and a sleek design.',\n",
              " 'labels': ['technology', 'device', 'health', 'fashion'],\n",
              " 'scores': [0.6615387797355652,\n",
              "  0.32739749550819397,\n",
              "  0.006408060435205698,\n",
              "  0.004655580502003431]}"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "> b) Text Generation\n",
        "\n"
      ],
      "metadata": {
        "id": "mhMvSAcjdw4I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "generator = pipeline(\"text-generation\")\n",
        "generator(\"You are so beautiful. I love you, but\")"
      ],
      "metadata": {
        "id": "Qwkn1wZaNCxn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca857c4a-303d-4700-9643-24756119a702"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to openai-community/gpt2 and revision 6c0e608 (https://huggingface.co/openai-community/gpt2).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
            "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'generated_text': 'You are so beautiful. I love you, but it feels like I\\'m in the middle of a dance.\"\\n\\n\"We\\'re a single family, right?\"\\n\\n\"No, I don\\'t know how I can even explain it to you'}]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generator = pipeline(\"text-generation\", model=\"distilgpt2\")\n",
        "generator(\n",
        "    \"You are so beautiful. I love you, but\",\n",
        "    max_length=30,\n",
        "    num_return_sequences=2,\n",
        ")"
      ],
      "metadata": {
        "id": "drVV_RinNMws",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a190fc6-8822-4b6a-dd9d-f4e17b9eacc7"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'generated_text': 'You are so beautiful. I love you, but it\\'s not my love.\"'},\n",
              " {'generated_text': 'You are so beautiful. I love you, but why am I here? I need you every night! I love you! Thank you!'}]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generator = pipeline(\"text-generation\", model=\"distilgpt2\")\n",
        "generator(\"In the future, space exploration will allow humans to\")"
      ],
      "metadata": {
        "id": "pv7R-U_gmGxF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1329d6d5-9ee9-4d08-9242-98117ad1ff44"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'generated_text': 'In the future, space exploration will allow humans to explore interstellar space and explore the future with little to no practical risk.\\n\\n\\n\\n\"Space exploration is a technological breakthrough but it will enable life in deep space to survive and prosper. The future'}]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "> c) Fill Mask\n",
        "\n"
      ],
      "metadata": {
        "id": "AfFBkGSad6XN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "unmasker = pipeline(\"fill-mask\")\n",
        "unmasker(\"The <mask> festival attracted people from all over the world.\", top_k=2)"
      ],
      "metadata": {
        "id": "-Ab97He7Dd0k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26205c39-5755-4f95-bf98-f138c0c51fcc"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to distilbert/distilroberta-base and revision ec58a5b (https://huggingface.co/distilbert/distilroberta-base).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
            "Some weights of the model checkpoint at distilbert/distilroberta-base were not used when initializing RobertaForMaskedLM: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "- This IS expected if you are initializing RobertaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'score': 0.07562767714262009,\n",
              "  'token': 1013,\n",
              "  'token_str': ' annual',\n",
              "  'sequence': 'The annual festival attracted people from all over the world.'},\n",
              " {'score': 0.06016301363706589,\n",
              "  'token': 930,\n",
              "  'token_str': ' music',\n",
              "  'sequence': 'The music festival attracted people from all over the world.'}]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "> d) Named Entity Recognition (NER)\n",
        "\n"
      ],
      "metadata": {
        "id": "0tTso06VeJfG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ner = pipeline(\"ner\", grouped_entities=True)\n",
        "ner(\"My name is Alif Naywa and I am undergraduate student at Yogyakarta State University\")"
      ],
      "metadata": {
        "id": "H-uxwPRKDhpB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0108118-4091-4673-f4ff-94fd792a90c1"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to dbmdz/bert-large-cased-finetuned-conll03-english and revision f2482bf (https://huggingface.co/dbmdz/bert-large-cased-finetuned-conll03-english).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
            "Some weights of the model checkpoint at dbmdz/bert-large-cased-finetuned-conll03-english were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
            "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'entity_group': 'PER',\n",
              "  'score': 0.99557364,\n",
              "  'word': 'Alif Naywa',\n",
              "  'start': 11,\n",
              "  'end': 21},\n",
              " {'entity_group': 'ORG',\n",
              "  'score': 0.9509055,\n",
              "  'word': 'Yogyakarta State University',\n",
              "  'start': 56,\n",
              "  'end': 83}]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "> e) Question Answering\n",
        "\n"
      ],
      "metadata": {
        "id": "gvTzrCYjeSqU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "qa_pipeline = pipeline(\"question-answering\", model=\"distilbert-base-cased-distilled-squad\")\n",
        "context = \"\"\"\n",
        "Indonesia adalah negara kepulauan terbesar di dunia dengan lebih dari 17.000 pulau.\n",
        "Ibukota negara ini adalah Jakarta, dan bahasa resminya adalah Bahasa Indonesia.\n",
        "Indonesia terkenal akan keanekaragaman budaya, bahasa, dan agamanya.\"\"\"\n",
        "question = \"Berapa banyak pulau yang ada di Indonesia?\"\n",
        "\n",
        "result = qa_pipeline(question=question, context=context)\n",
        "print(f\"Jawaban: {result['answer']}\")"
      ],
      "metadata": {
        "id": "1SbkDlwfDlF5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f44ae91-f2a4-4720-c6ea-c3ac88e67269"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Jawaban: 17.000 pulau\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "qa_pipeline = pipeline(\"question-answering\", model=\"distilbert-base-cased-distilled-squad\")\n",
        "context =  \"\"\"\n",
        "Candi Borobudur adalah candi yang terletak di Magelang, Jawa Tengah, Indonesia.\n",
        "Candi ini dibangun pada abad ke-8 oleh Dinasti Syailendra. Borobudur merupakan salah satu situs Warisan Dunia UNESCO dan merupakan candi Buddha terbesar di dunia.\n",
        "\"\"\"\n",
        "question = \"Candi Borobudur terletak dimana?\"\n",
        "\n",
        "result = qa_pipeline(question=question, context=context)\n",
        "print(f\"Jawaban: {result['answer']}\")"
      ],
      "metadata": {
        "id": "8Y1wD47GplfT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d92a815f-ed13-4b4f-b375-740fb4d1ec16"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Jawaban: Magelang\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "> f) Sentiment Analysis\n",
        "\n"
      ],
      "metadata": {
        "id": "fd82JFQoedE6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classifier = pipeline(\"sentiment-analysis\")\n",
        "classifier(\"You are as beautiful as the day I lost you.\")"
      ],
      "metadata": {
        "id": "U3IZcIeAE41r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ba13f3a-8d0b-4915-f99c-57a93f8219f8"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
            "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'label': 'POSITIVE', 'score': 0.9998743534088135}]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "> g) Summarization\n",
        "\n"
      ],
      "metadata": {
        "id": "txBUK5MFelto"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "summarizer = pipeline(\"summarization\")\n",
        "summarizer(\n",
        "    \"\"\"\n",
        "    Indonesia, yang terletak di Asia Tenggara, adalah negara kepulauan terbesar di dunia dengan lebih dari 17.000 pulau.\n",
        "    Negara ini memiliki beragam budaya, bahasa, dan agama yang mencerminkan keragaman masyarakatnya.\n",
        "    Indonesia adalah rumah bagi lebih dari 270 juta orang, menjadikannya sebagai negara berpenduduk terbesar keempat di dunia.\n",
        "    Ibukota Indonesia adalah Jakarta, yang terletak di pulau Jawa. Selain itu, Indonesia dikenal dengan keindahan alamnya, termasuk hutan hujan tropis, gunung berapi, dan pantai yang menakjubkan.\n",
        "    Masyarakat Indonesia terkenal dengan keramahtamahannya dan keanekaragaman kulinernya yang kaya, dengan berbagai hidangan tradisional yang beragam dari setiap daerah.\n",
        "\n",
        "    Perekonomian Indonesia merupakan salah satu yang terbesar di Asia Tenggara dan didukung oleh berbagai sektor, termasuk pertanian, manufaktur, dan pariwisata.\n",
        "    Pemerintah Indonesia berupaya untuk meningkatkan infrastruktur dan investasi asing untuk memperkuat pertumbuhan ekonomi.\n",
        "    Namun, negara ini juga menghadapi berbagai tantangan, seperti masalah lingkungan, kemiskinan, dan ketidaksetaraan.\n",
        "    Dengan berbagai inisiatif dan program, pemerintah dan masyarakat Indonesia berusaha untuk menciptakan masa depan yang lebih baik bagi generasi mendatang.\n",
        "    Dalam beberapa tahun terakhir, sektor teknologi informasi dan komunikasi telah tumbuh pesat, dengan semakin banyaknya startup dan inovasi digital yang bermunculan di seluruh negeri.\n",
        "    \"\"\"\n",
        ")"
      ],
      "metadata": {
        "id": "rXSjHIImDptH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54f3c727-1db5-4dec-eea2-0c79df0ba768"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to sshleifer/distilbart-cnn-12-6 and revision a4f8f3e (https://huggingface.co/sshleifer/distilbart-cnn-12-6).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
            "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'summary_text': ' Indonesia adalah rumah bagi lebih dari 270 juta orang, menjadikannya sebagai negara berpenduduk terbesar keempat di dunia . Negara ini memiliki beragam budaya, bahasa, dan agama yang mencerminkan keragaman masyarakatnya .'}]"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "> h) Translation\n",
        "\n"
      ],
      "metadata": {
        "id": "SQfv5TpFeqEe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "translator = pipeline(\"translation\", model=\"Helsinki-NLP/opus-mt-id-en\")\n",
        "\n",
        "text_to_translate = \"melihatmu senyummu yang manis, membuatku jatuh cinta\"\n",
        "result = translator(text_to_translate)\n",
        "\n",
        "print(result[0]['translation_text'])"
      ],
      "metadata": {
        "id": "Wxr6a3YYDtmL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "253723d8-dec0-4c91-e940-95a05cce39d7"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seeing you smile sweetly, makes me fall in love\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Analisis\n",
        "\n",
        "1. Zero Shot Classification\n",
        "\n",
        "Zero-shot classification merupakan teknik yang sangat bermanfaat dalam klasifikasi teks. Output yang dianalisis menunjukkan bagaimana model dapat dengan efektif mengevaluasi teks dan memberikan label yang paling relevan berdasarkan skor kepercayaan.\n",
        "\n",
        "2. Text Generation\n",
        "\n",
        "Text generation merupakan alat yang mampu menciptakan teks baru yang relevan dengan input. Hasil yang dianalisis menunjukkan kemampuan model untuk menghasilkan kalimat yang ekspresif,\n",
        "\n",
        "3. Fill Mask\n",
        "\n",
        "Fill mask adalah teknik yang efektif dalam pemrosesan bahasa alami untuk memprediksi kata yang hilang dalam kalimat.Hasil analisis output menunjukkan kemampuan model untuk mengisi kata yang relevan berdasarkan konteks kalimat, meskipun skor yang dihasilkan menunjukkan tingkat kepercayaan yang bervariasi.\n",
        "\n",
        "4. Named Entity Recognition (NER)\n",
        "\n",
        "Named Entity Recognition (NER) merupakan alat dalam analisis teks yang memungkinkan identifikasi dan klasifikasi entitas kunci. Output yang dianalisis menunjukkan kemampuan model untuk secara akurat mengidentifikasi individu dan organisasi, serta memberikan skor kepercayaan yang tinggi pada klasifikasi tersebut.\n",
        "\n",
        "5. Question Answering\n",
        "\n",
        "Question answering adalah alat dalam pemrosesan bahasa alami yang memungkinkan pengguna untuk mendapatkan jawaban cepat dan akurat terhadap pertanyaan yang diajukan. Output yang dianalisis menunjukkan kemampuan sistem QA dalam memberikan jawaban numerik yang tepat.\n",
        "\n",
        "6. Sentiment Analysis\n",
        "\n",
        "Sentiment analysis adalah alat yang berguna dalam memahami emosi dan opini yang terdapat dalam teks. Sentiment analysis dapat digunakan dalam berbagai konteks termasuk pemasaran, analisis media sosial, dan umpan balik pelanggan.\n",
        "\n",
        "7. Summarization\n",
        "\n",
        "Summarization adalah alat untuk menyajikan informasi secara ringkas dan jelas. Output yang dianalisis menunjukkan bahwa model mampu menghasilkan ringkasan yang informatif dari teks yang panjang.\n",
        "\n",
        "8. Translation\n",
        "\n",
        "Translation adalah alat untuk mengubah suatu bahasa menjadi ke bahasa lain."
      ],
      "metadata": {
        "id": "FJ2DD_XpY6PC"
      }
    }
  ]
}